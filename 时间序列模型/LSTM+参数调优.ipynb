{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e664f6",
   "metadata": {},
   "source": [
    "## 导入库和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae617988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87537d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row1</th>\n",
       "      <th>Row2</th>\n",
       "      <th>Row3</th>\n",
       "      <th>Row4</th>\n",
       "      <th>Row5</th>\n",
       "      <th>Row6</th>\n",
       "      <th>Row7</th>\n",
       "      <th>Row8</th>\n",
       "      <th>Row9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-06-19</th>\n",
       "      <td>0.009400</td>\n",
       "      <td>-0.241265</td>\n",
       "      <td>-0.062255</td>\n",
       "      <td>0.396046</td>\n",
       "      <td>-0.200110</td>\n",
       "      <td>0.892711</td>\n",
       "      <td>7.741112</td>\n",
       "      <td>7.042818</td>\n",
       "      <td>15.161542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-20</th>\n",
       "      <td>0.021499</td>\n",
       "      <td>-0.235724</td>\n",
       "      <td>-0.091477</td>\n",
       "      <td>0.399708</td>\n",
       "      <td>-0.203983</td>\n",
       "      <td>0.895268</td>\n",
       "      <td>7.745161</td>\n",
       "      <td>7.045542</td>\n",
       "      <td>15.164007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-23</th>\n",
       "      <td>-0.003928</td>\n",
       "      <td>-0.211690</td>\n",
       "      <td>-0.083402</td>\n",
       "      <td>0.392153</td>\n",
       "      <td>-0.203865</td>\n",
       "      <td>0.896612</td>\n",
       "      <td>7.749445</td>\n",
       "      <td>7.048199</td>\n",
       "      <td>15.166476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-24</th>\n",
       "      <td>-0.004123</td>\n",
       "      <td>-0.254588</td>\n",
       "      <td>-0.035452</td>\n",
       "      <td>0.373585</td>\n",
       "      <td>-0.199849</td>\n",
       "      <td>0.896718</td>\n",
       "      <td>7.753970</td>\n",
       "      <td>7.050790</td>\n",
       "      <td>15.168949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-25</th>\n",
       "      <td>-0.036716</td>\n",
       "      <td>-0.274480</td>\n",
       "      <td>0.029313</td>\n",
       "      <td>0.345070</td>\n",
       "      <td>-0.192232</td>\n",
       "      <td>0.895568</td>\n",
       "      <td>7.758738</td>\n",
       "      <td>7.053315</td>\n",
       "      <td>15.171426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Row1      Row2      Row3      Row4      Row5      Row6  \\\n",
       "trade_date                                                               \n",
       "2014-06-19  0.009400 -0.241265 -0.062255  0.396046 -0.200110  0.892711   \n",
       "2014-06-20  0.021499 -0.235724 -0.091477  0.399708 -0.203983  0.895268   \n",
       "2014-06-23 -0.003928 -0.211690 -0.083402  0.392153 -0.203865  0.896612   \n",
       "2014-06-24 -0.004123 -0.254588 -0.035452  0.373585 -0.199849  0.896718   \n",
       "2014-06-25 -0.036716 -0.274480  0.029313  0.345070 -0.192232  0.895568   \n",
       "\n",
       "                Row7      Row8       Row9  \n",
       "trade_date                                 \n",
       "2014-06-19  7.741112  7.042818  15.161542  \n",
       "2014-06-20  7.745161  7.045542  15.164007  \n",
       "2014-06-23  7.749445  7.048199  15.166476  \n",
       "2014-06-24  7.753970  7.050790  15.168949  \n",
       "2014-06-25  7.758738  7.053315  15.171426  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"example_data_transposed.csv\",parse_dates=[\"trade_date\"],index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9efccb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\"Row9\"]\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc96c9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2381, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_split=round(len(df)*0.20)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b2b43e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340, 1)\n",
      "(1041, 1)\n"
     ]
    }
   ],
   "source": [
    "df_for_training=df[:-1041]\n",
    "df_for_testing=df[-1041:]\n",
    "print(df_for_training.shape)\n",
    "print(df_for_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9083df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232b860",
   "metadata": {},
   "source": [
    "## 进行minmax标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65adb0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00],\n",
       "       [4.45162492e-04],\n",
       "       [8.91070870e-04],\n",
       "       ...,\n",
       "       [9.98297341e-01],\n",
       "       [9.99148739e-01],\n",
       "       [1.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_for_training_scaled = scaler.fit_transform(df_for_training)\n",
    "df_for_testing_scaled=scaler.transform(df_for_testing)\n",
    "df_for_training_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef99fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXY(dataset,n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(dataset)):\n",
    "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
    "            dataY.append(dataset[i,0])\n",
    "    return np.array(dataX),np.array(dataY)\n",
    " \n",
    " \n",
    "    trainX,trainY=createXY(df_for_training_scaled,30)\n",
    "testX,testY=createXY(df_for_testing_scaled,30)\n",
    "trainX,trainY=createXY(df_for_training_scaled,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab863d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX Shape--  (1310, 30, 1)\n",
      "trainY Shape--  (1310,)\n",
      "testX Shape--  (1011, 30, 1)\n",
      "testY Shape--  (1011,)\n"
     ]
    }
   ],
   "source": [
    "print(\"trainX Shape-- \",trainX.shape)\n",
    "print(\"trainY Shape-- \",trainY.shape)\n",
    "\n",
    " \n",
    "print(\"testX Shape-- \",testX.shape)\n",
    "print(\"testY Shape-- \",testY.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584e43e",
   "metadata": {},
   "source": [
    "## 定义LSTM模型+优化参数算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f1ce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-02a27f7b2eb5>:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  grid_model = KerasRegressor(build_fn=build_model,verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "41/41 [==============================] - 4s 37ms/step - loss: 0.1022 - val_loss: 0.0345\n",
      "Epoch 2/8\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0065 - val_loss: 0.0466\n",
      "Epoch 3/8\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 4/8\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 5/8\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0049 - val_loss: 7.4506e-04\n",
      "Epoch 6/8\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.0045 - val_loss: 4.4187e-04\n",
      "Epoch 7/8\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0038 - val_loss: 4.7447e-04\n",
      "Epoch 8/8\n",
      "41/41 [==============================] - 1s 18ms/step - loss: 0.0037 - val_loss: 6.9559e-04\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 1/8\n",
      "41/41 [==============================] - 4s 36ms/step - loss: 0.0078 - val_loss: 0.0330\n",
      "Epoch 2/8\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 6.5240e-04 - val_loss: 0.0183\n",
      "Epoch 3/8\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.7652e-04 - val_loss: 0.0186\n",
      "Epoch 4/8\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 5.0708e-04 - val_loss: 0.0397\n",
      "Epoch 5/8\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 4.2845e-04 - val_loss: 0.0147\n",
      "Epoch 6/8\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 3.7719e-04 - val_loss: 0.0118\n",
      "Epoch 7/8\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.4979e-04 - val_loss: 0.0234\n",
      "Epoch 8/8\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.2765e-04 - val_loss: 0.0150\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4.5871e-05\n",
      "Epoch 1/8\n",
      "41/41 [==============================] - 4s 36ms/step - loss: 0.5079 - val_loss: 1.8833\n",
      "Epoch 2/8\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.5016 - val_loss: 1.8573\n",
      "Epoch 3/8\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.4911 - val_loss: 1.8306\n",
      "Epoch 4/8\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.4826 - val_loss: 1.8030\n",
      "Epoch 5/8\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.4772 - val_loss: 1.7749\n",
      "Epoch 6/8\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.4661 - val_loss: 1.7461\n",
      "Epoch 7/8\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.4589 - val_loss: 1.7167\n",
      "Epoch 8/8\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.4479 - val_loss: 1.6867\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0464\n",
      "Epoch 1/8\n",
      "41/41 [==============================] - 4s 39ms/step - loss: 0.0533 - val_loss: 1.8391\n",
      "Epoch 2/8\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0527 - val_loss: 1.8267\n",
      "Epoch 3/8\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0517 - val_loss: 1.8143\n",
      "Epoch 4/8\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0513 - val_loss: 1.8016\n",
      "Epoch 5/8\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0506 - val_loss: 1.7888\n",
      "Epoch 6/8\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0501 - val_loss: 1.7756\n",
      "Epoch 7/8\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0498 - val_loss: 1.7625\n",
      "Epoch 8/8\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0488 - val_loss: 1.7493\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.4568\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 4s 42ms/step - loss: 0.0415 - val_loss: 0.0694\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0061 - val_loss: 0.0312\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0037 - val_loss: 1.2540e-04\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0037 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0040 - val_loss: 0.0111\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2.1023e-04\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 4s 37ms/step - loss: 0.0050 - val_loss: 0.0340\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 6.1685e-04 - val_loss: 0.0146\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 5.4617e-04 - val_loss: 0.0141\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.2265e-04 - val_loss: 0.0028\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 4.1994e-04 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 4.1051e-04 - val_loss: 0.0305\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 5.9892e-04 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 4.5953e-04 - val_loss: 0.0070\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 3.8548e-04 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 3.5599e-04 - val_loss: 0.0145\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 4s 37ms/step - loss: 0.6979 - val_loss: 2.5109\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.6899 - val_loss: 2.4860\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.6835 - val_loss: 2.4608\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.6783 - val_loss: 2.4351\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.6624 - val_loss: 2.4095\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.6615 - val_loss: 2.3833\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.6502 - val_loss: 2.3568\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.6455 - val_loss: 2.3301\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.6329 - val_loss: 2.3032\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.6226 - val_loss: 2.2759\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0660\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 4s 39ms/step - loss: 0.0580 - val_loss: 1.9399\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 1s 21ms/step - loss: 0.0575 - val_loss: 1.9233\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0563 - val_loss: 1.9065\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0552 - val_loss: 1.8896\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 0.0547 - val_loss: 1.8726\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0537 - val_loss: 1.8553\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0528 - val_loss: 1.8380\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0519 - val_loss: 1.8206\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 1s 22ms/step - loss: 0.0506 - val_loss: 1.8031\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 1s 23ms/step - loss: 0.0499 - val_loss: 1.7856\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.4746\n",
      "Epoch 1/8\n",
      "33/33 [==============================] - 4s 48ms/step - loss: 0.0607 - val_loss: 0.0498\n",
      "Epoch 2/8\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0073 - val_loss: 0.0572\n",
      "Epoch 3/8\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0057 - val_loss: 0.0236\n",
      "Epoch 4/8\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0040 - val_loss: 0.0079\n",
      "Epoch 6/8\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 7/8\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 8/8\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.3410e-04\n",
      "Epoch 1/8\n",
      "33/33 [==============================] - 4s 42ms/step - loss: 0.0062 - val_loss: 0.0164\n",
      "Epoch 2/8\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 7.6614e-04 - val_loss: 0.0028\n",
      "Epoch 3/8\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 6.0171e-04 - val_loss: 0.0030\n",
      "Epoch 4/8\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 4.0987e-04 - val_loss: 0.0044\n",
      "Epoch 5/8\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 4.3273e-04 - val_loss: 0.0114\n",
      "Epoch 6/8\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 4.4723e-04 - val_loss: 0.0100\n",
      "Epoch 7/8\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 3.6710e-04 - val_loss: 0.0025\n",
      "Epoch 8/8\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 3.8754e-04 - val_loss: 0.0012\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 1/8\n",
      "33/33 [==============================] - 4s 41ms/step - loss: 0.4986 - val_loss: 1.8703\n",
      "Epoch 2/8\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.4937 - val_loss: 1.8551\n",
      "Epoch 3/8\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.4871 - val_loss: 1.8393\n",
      "Epoch 4/8\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.4828 - val_loss: 1.8235\n",
      "Epoch 5/8\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.4738 - val_loss: 1.8073\n",
      "Epoch 6/8\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.4720 - val_loss: 1.7908\n",
      "Epoch 7/8\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.4659 - val_loss: 1.7741\n",
      "Epoch 8/8\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.4626 - val_loss: 1.7570\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0481\n",
      "Epoch 1/8\n",
      "33/33 [==============================] - 4s 41ms/step - loss: 0.0542 - val_loss: 1.7405\n",
      "Epoch 2/8\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0535 - val_loss: 1.7223\n",
      "Epoch 3/8\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0524 - val_loss: 1.7041\n",
      "Epoch 4/8\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.0514 - val_loss: 1.6853\n",
      "Epoch 5/8\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0503 - val_loss: 1.6667\n",
      "Epoch 6/8\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0500 - val_loss: 1.6479\n",
      "Epoch 7/8\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0483 - val_loss: 1.6290\n",
      "Epoch 8/8\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0473 - val_loss: 1.6102\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4364\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 4s 44ms/step - loss: 0.1297 - val_loss: 0.0510\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0072 - val_loss: 0.0218\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0042 - val_loss: 2.1983e-04\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0036 - val_loss: 6.5692e-05\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 0.0036 - val_loss: 6.9545e-04\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 4s 44ms/step - loss: 0.0091 - val_loss: 0.0276\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 8.0050e-04 - val_loss: 0.0271\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 4.6459e-04 - val_loss: 0.0153\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 4.2303e-04 - val_loss: 0.0180\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 4.2997e-04 - val_loss: 0.0308\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 4.1666e-04 - val_loss: 0.0407\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 4.0588e-04 - val_loss: 0.0235\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 3.6443e-04 - val_loss: 0.0291\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 3.3913e-04 - val_loss: 0.0339\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 3.6350e-04 - val_loss: 0.0372\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 4s 41ms/step - loss: 0.4686 - val_loss: 1.7770\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.4599 - val_loss: 1.7589\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.4569 - val_loss: 1.7403\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.4512 - val_loss: 1.7213\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.4451 - val_loss: 1.7019\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.4389 - val_loss: 1.6823\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.4319 - val_loss: 1.6623\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.4272 - val_loss: 1.6421\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.4196 - val_loss: 1.6213\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.4099 - val_loss: 1.6004\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0413\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 4s 39ms/step - loss: 0.0595 - val_loss: 1.9701\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0592 - val_loss: 1.9590\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0587 - val_loss: 1.9479\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0579 - val_loss: 1.9366\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0576 - val_loss: 1.9252\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0571 - val_loss: 1.9135\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0566 - val_loss: 1.9017\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0555 - val_loss: 1.8899\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0552 - val_loss: 1.8779\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 0.0538 - val_loss: 1.8659\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5024\n",
      "Epoch 1/10\n",
      "82/82 [==============================] - 4s 25ms/step - loss: 0.0175 - val_loss: 0.0126\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 1s 16ms/step - loss: 0.0025 - val_loss: 0.0143\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 1s 16ms/step - loss: 0.0026 - val_loss: 0.0287\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 1s 16ms/step - loss: 0.0018 - val_loss: 0.0142\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 1s 16ms/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 1s 16ms/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 1s 16ms/step - loss: 0.0018 - val_loss: 0.0120\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 1s 16ms/step - loss: 0.0019 - val_loss: 0.0339\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 1s 16ms/step - loss: 0.0018 - val_loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "82/82 [==============================] - 1s 15ms/step - loss: 0.0017 - val_loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "def build_model(optimizer):\n",
    "    grid_model = Sequential()\n",
    "    grid_model.add(LSTM(50,return_sequences=True,input_shape=(30,1)))\n",
    "    grid_model.add(LSTM(50))\n",
    "    grid_model.add(Dropout(0.2))\n",
    "    grid_model.add(Dense(1))\n",
    "\n",
    "    grid_model.compile(loss = 'mse',optimizer = optimizer)\n",
    "    return grid_model\n",
    "\n",
    "grid_model = KerasRegressor(build_fn=build_model,verbose=1)\n",
    "parameters = {'batch_size' : [16,20],\n",
    "              'epochs' : [8,10],\n",
    "              'optimizer' : ['adam','Adadelta'] }\n",
    "\n",
    "grid_search  = GridSearchCV(estimator = grid_model,\n",
    "                            param_grid = parameters,\n",
    "                            cv = 2)\n",
    "grid_search = grid_search.fit(trainX,trainY,validation_data=(testX,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2159ace",
   "metadata": {},
   "source": [
    "输出LSTM模型的最优参数，重新定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb2f93",
   "metadata": {},
   "source": [
    "batch_size: 批量大小，表示在训练过程中每次输入给模型的样本数量。训练时数据通常会被分成多个批次进行处理，每个批次包含指定数量的样本。在这里，batch_size被设置为20，意味着每次训练时，模型会接收20个样本，并使用这20个样本的平均梯度来更新模型的权重。\n",
    "\n",
    "epochs: 迭代次数，表示在整个训练数据上重复训练的次数。在每个迭代期间，模型会遍历所有的训练样本，通过反向传播和优化算法来更新模型的权重。在这里，epochs被设置为10，意味着整个训练数据会被遍历10次。\n",
    "\n",
    "optimizer: 优化器，用于更新模型的权重以最小化损失函数。在这里，使用了Adam优化器，它是一种常用的自适应学习率优化算法，可以帮助加速神经网络的训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aad56d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16, 'epochs': 10, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f15a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model=grid_search.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3461d575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 5ms/step\n",
      "prediction\n",
      " [[1.0418345]\n",
      " [1.0426185]\n",
      " [1.0434021]\n",
      " ...\n",
      " [1.5622033]\n",
      " [1.562431 ]\n",
      " [1.562658 ]]\n",
      "\n",
      "Prediction Shape- (1011, 1)\n"
     ]
    }
   ],
   "source": [
    "prediction=my_model.predict(testX)\n",
    "print(\"prediction\\n\", prediction)\n",
    "print(\"\\nPrediction Shape-\",prediction.shape) #重新进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c407992e",
   "metadata": {},
   "source": [
    "在将时间序列数据转换为多时间步的输入序列时，进行数据扩增（data augmentation）等情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7eb80",
   "metadata": {},
   "source": [
    "在LSTM模型的预测中使用np.repeat函数通常是为了将预测结果进行重复，从而使其与输入数据的形状保持一致，以便进行比较或进一步处理。\n",
    "\n",
    "当使用LSTM进行时间序列预测时，通常会将输入数据组织成多个时间步的序列，例如每个时间步包含过去几天的数据。LSTM模型在进行预测时，会生成未来某个时间步的预测值，通常是单个时间步的预测。\n",
    "\n",
    "然而，为了将预测结果与输入数据进行对应，有时需要将预测值复制多次，使其与输入数据的时间步数相同。这就是使用np.repeat函数的目的。\n",
    "\n",
    "让我们假设有一个LSTM模型进行销售量预测，我们使用过去5天的销售量作为输入来预测未来1天的销售量。LSTM模型会生成一个预测值，但是我们希望将这个预测值与过去5天的销售量进行对应，这样更方便进行比较和可视化。\n",
    "\n",
    "例如，假设LSTM模型预测的销售量为prediction = [100]，我们使用np.repeat(prediction, 5, axis=-1)，将其重复5次，得到prediction_copies_array = [100, 100, 100, 100, 100]，然后将prediction_copies_array与过去5天的销售量进行对应。这样，我们就可以将预测值与输入数据形状一致，方便后续的处理和分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86535534",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_copies_array = np.repeat(prediction,30, axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c86eba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1011, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_copies_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c0508",
   "metadata": {},
   "source": [
    "scaler.inverse_transform: 这是MinMaxScaler对象的逆转换方法，用于将归一化后的数据还原回原始数据范围。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ca1172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=scaler.inverse_transform(np.reshape(prediction_copies_array,(len(prediction),30)))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c8c1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_copies_array = np.repeat(testY,30, axis=-1)\n",
    "original=scaler.inverse_transform(np.reshape(original_copies_array,(len(testY),30)))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "facc1218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred Values--  [20.930216 20.934555 20.938894 ... 23.811514 23.812777 23.814034]\n",
      "\n",
      "Original Values--  [20.84429222 20.84897917 20.85366523 ... 24.49422085 24.49615282\n",
      " 24.49808021]\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred Values-- \" ,pred)\n",
    "print(\"\\nOriginal Values-- \" ,original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74579de4",
   "metadata": {},
   "source": [
    "## 做出预测值和真实值随着时间对比的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf7b909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(original, color = 'red', label = 'Real Stock Price')\n",
    "plt.plot(pred, color = 'blue', label = 'Predicted Stock Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(' Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde1b8d",
   "metadata": {},
   "source": [
    "## RMSE、MAE法检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a70e83c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3576392266459654\n",
      "MAE: 0.28333599963734857\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 示例真实值和预测值\n",
    "y_true = original\n",
    "y_pred = pred\n",
    "\n",
    "# 计算均方根误差（RMSE）\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# 计算平均绝对误差（MAE）\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f906555a",
   "metadata": {},
   "source": [
    "## 进行外推预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b73bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "外推预测的价格： [[1.562658]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# 假设模型用过去30天的价格预测未来1天的价格\n",
    "# 这里用示例数据代替\n",
    "history_sales = testX[-1:]  # 过去30天的价格\n",
    "\n",
    "\n",
    "# 使用模型进行外推预测\n",
    "predicted_sales = my_model.predict(history_sales)\n",
    "\n",
    "print(\"外推预测的价格：\", predicted_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bada9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_copies_array = np.repeat(predicted_sales,30, axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48ae943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=scaler.inverse_transform(predicted_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "306c23fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.814034]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0345b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
